[general]
episodes = 10000

[env]
num_qubits = 2
num_layers = 30
err_mitig = 0
rand_halt = 0
decomposed = 1


n_shots = 0
noise_models = 0
noise_values = 0

fake_min_energy = -3
fn_type = incremental_with_fixed_ends
accept_err = 2
shift_threshold_time = 500
shift_threshold_ball = 0.5e-3
success_thresh = 25
succ_radius_shift = 10
succes_switch = 2
thresholds = []
switch_episodes = []
curriculum_type = MovingThreshold

[problem]
ham_type = tfim
ham_model = 2q_j1_h1

[agent]
batch_size = 1000
memory_size = 20000
neurons = [1000,1000,1000,1000,1000]
dropout = 0.
learning_rate = 0.0001
angles = 0
en_state = 1
agent_type = DeepQ_synthesized
agent_class = DQN_synthesized
init_net = 0

update_target_net = 500
final_gamma = 0.005
epsilon_decay = 0.99995
epsilon_min = 0.05
epsilon_restart = 1.0

[non_local_opt]

a = 0.8085
alpha = 0.9352
c = 0.0570
gamma = 0.0152
lamda = 0.5735
beta_1 = 0.7677
beta_2 = 0.9932

maxfev = 500

global_iters = 1000
method = scipy_each_step
optim_alg = COBYLA






